{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own model with your data\n",
    "This notebook shows you how to train a model for your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.sm_utils import parse_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stack_outputs.json\") as f:\n",
    "    sagemaker_config = json.load(f)\n",
    "s3_bucket = sagemaker_config[\"S3Bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Get the `output.manifest` file from the labelling job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_job_id = \"{}-labelling-job\".format(sagemaker_config[\"SolutionPrefix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "# output manifest of the labelling job\n",
    "output_manifest_location = \"custom_data/output/{}/manifests/output/output.manifest\".format(\n",
    "    label_job_id)\n",
    "\n",
    "item_object = s3_client.get_object(Bucket=s3_bucket, \n",
    "                                   Key=output_manifest_location)\n",
    "body = item_object['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size = 0.8, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_manifest(entries, train_or_test):\n",
    "    with open(\"{}.manifest\".format(train_or_test), \"w\") as f:\n",
    "        for entry in entries:\n",
    "            f.write(entry+\"\\n\")\n",
    "            if len(entry) == 0:\n",
    "                continue\n",
    "            json_entry = json.loads(entry)\n",
    "            source_image_bucket, source_image_key = parse_s3_url(json_entry[\"source-ref\"])\n",
    "            copy_location = \"custom_data/training/{}/{}\".format(\n",
    "                train_or_test, os.path.basename(source_image_key))\n",
    "            s3_client.copy(CopySource={\"Key\": source_image_key, \n",
    "                                       \"Bucket\": source_image_bucket},\n",
    "                           Bucket=s3_bucket,\n",
    "                           Key=copy_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_size+test_size == 1.0, \"train + test must be equal to 1.0\"\n",
    "\n",
    "train_entries, test_entries = train_test_split(\n",
    "    body.split(\"\\n\"), train_size=train_size, test_size=test_size)\n",
    "\n",
    "process_manifest(train_entries, \"train\")\n",
    "process_manifest(train_entries, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp train.manifest s3://$s3_bucket/custom_data/training/train/train.manifest\n",
    "!aws s3 cp test.manifest s3://$s3_bucket/custom_data/training/test/test.manifest\n",
    "\n",
    "!rm train.manifest\n",
    "!rm test.manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word segmentation\n",
    "In this section we will train an object detection model to locate all the words in the image passage.\n",
    "You can look into the details of the model and algorithm in `src/word_and_line_segmentation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_segmentation_parameters = {    \n",
    "    \"min_c\": 0.01,\n",
    "    \"overlap_thres\": 0.10,\n",
    "    \"topk\": 150,\n",
    "    \"epoch\": 401,\n",
    "    \"image_size\": 500,\n",
    "    \"expand_bb_scale\": 0.00,\n",
    "    \"batch_size\": 1,\n",
    "    \"gpu_count\": 1,\n",
    "    \n",
    "    \"train_path\": \"train\",\n",
    "    \"train_annotation_filename\": \"train.manifest\",\n",
    "    \n",
    "    \"test_path\": \"test\",\n",
    "    \"test_annotation_filename\": \"test.manifest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'Epoch', 'Regex': 'Epoch: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'train_loss', 'Regex': 'train_loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'test_loss',  'Regex': 'test_loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'test accuracy',  'Regex': 'test accuracy: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'mae', 'Regex': 'mae: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "role = sagemaker_config[\"SageMakerIamRole\"]\n",
    "\n",
    "estimator = MXNet(entry_point='word_and_line_segmentation.py',\n",
    "                  source_dir='src',\n",
    "                  role=role,\n",
    "                  train_instance_type=sagemaker_config[\"SageMakerTrainingInstanceType\"],\n",
    "                  train_instance_count=1,\n",
    "                  output_path=\"s3://\"+s3_bucket+\"/word_segmentation_training/\",\n",
    "                  framework_version='1.6.0',\n",
    "                  py_version='py3',\n",
    "                  metric_definitions=metric_definitions,\n",
    "                  base_job_name=sagemaker_config[\"SolutionPrefix\"]+\"-word-seg\",\n",
    "                  hyperparameters=word_segmentation_parameters,\n",
    "                  sagemaker_session=session\n",
    "                 )\n",
    "\n",
    "estimator.fit({\"train\": \"s3://{}/custom_data/training/\".format(s3_bucket)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting recognition\n",
    "In this section we will train an handwriting recognition model to transcribe all the words in a line.\n",
    "You can look into the details of the model and algorithm in `src/handwriting_line_recognition.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'Epoch', 'Regex': 'Epoch: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'train_loss', 'Regex': 'train_loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'test_loss',  'Regex': 'test_loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handwriting_recognition_parameters = {    \n",
    "    \"learning_rate\": 0.00005,\n",
    "    \"random_x_translation\": 0.10,\n",
    "    \"random_y_translation\": 0.10,\n",
    "    \"random_x_scaling\": 0.01,\n",
    "    \"random_y_scaling\": 0.1,\n",
    "    \n",
    "    \"batch_size\": 1,\n",
    "    \n",
    "    \"rnn_layers\": 1,\n",
    "    \"rnn_hidden_states\": 128,\n",
    "    \"line_or_word\": \"word\",\n",
    "    \n",
    "    \"train_path\": \"train\",\n",
    "    \"train_annotation_filename\": \"train.manifest\",\n",
    "    \n",
    "    \"test_path\": \"test\",\n",
    "    \"test_annotation_filename\": \"test.manifest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "role = sagemaker_config[\"SageMakerIamRole\"]\n",
    "\n",
    "estimator = MXNet(entry_point='handwriting_line_recognition.py',\n",
    "                  source_dir='src',\n",
    "                  role=role,\n",
    "                  train_instance_type=sagemaker_config[\"SageMakerTrainingInstanceType\"],\n",
    "                  train_instance_count=1,\n",
    "                  output_path=\"s3://\"+s3_bucket+\"/handwriting_line_recognition/\",\n",
    "                  framework_version='1.6.0',\n",
    "                  py_version='py3',\n",
    "                  metric_definitions=metric_definitions,\n",
    "                  base_job_name=sagemaker_config[\"SolutionPrefix\"]+\"-line-reg\",\n",
    "                  hyperparameters=handwriting_recognition_parameters,\n",
    "                  sagemaker_session=session,\n",
    "                 )\n",
    "\n",
    "estimator.fit({\"train\": \"s3://{}/custom_data/training/\".format(s3_bucket)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "- Click [here](./2_label_own_data.ipynb) to create a new labelling job \n",
    "- Click [here](./5_endpoint_updates.ipynb) to make a sagemaker endpoint with your new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MXNet JumpStart)",
   "language": "python",
   "name": "HUB_1P_IMAGE"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
